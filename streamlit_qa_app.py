"""
ì§ˆë¬¸-ë‹µë³€ ê¸°ë°˜ ì œí’ˆ ì¶”ì²œ Streamlit ì•±
ì‹œë§¨í‹± ê²€ìƒ‰ì„ í†µí•œ ë§ì¶¤í˜• ì œí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ
"""

import streamlit as st
import os
import json
import re
import time
from typing import List, Dict, Optional
import logging
from datetime import datetime

import openai
from supabase import create_client, Client
from sentence_transformers import SentenceTransformer

# ë°ì´í„° ìˆ˜ì§‘ ë° QA ìƒì„± ëª¨ë“ˆ import
# from data_collector import NaverDataCollector
# from qa_generator import QAGenerator

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¤– AI ì œí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========================================
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ========================================

@st.cache_resource
def init_clients():
    """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    try:
        # API í‚¤ í™•ì¸
        if hasattr(st, 'secrets') and 'SUPABASE_URL' in st.secrets:
            supabase_url = st.secrets["SUPABASE_URL"]
            supabase_key = st.secrets["SUPABASE_KEY"]
            naver_client_id = st.secrets["NAVER_CLIENT_ID"]
            naver_client_secret = st.secrets["NAVER_CLIENT_SECRET"]
            openai_api_key = st.secrets["OPENAI_API_KEY"]
        else:
            supabase_url = os.environ.get("SUPABASE_URL")
            supabase_key = os.environ.get("SUPABASE_KEY")
            naver_client_id = os.environ.get("NAVER_CLIENT_ID")
            naver_client_secret = os.environ.get("NAVER_CLIENT_SECRET")
            openai_api_key = os.environ.get("OPENAI_API_KEY")
        
        if not all([supabase_url, supabase_key, openai_api_key]):
            st.error("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.stop()
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        supabase = create_client(supabase_url, supabase_key)
        openai.api_key = openai_api_key
        
        return supabase, naver_client_id, naver_client_secret, openai_api_key
        
    except Exception as e:
        st.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        st.stop()

@st.cache_resource
def load_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ ë¡œë”©"""
    try:
        model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        return model
    except:
        try:
            model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            return model
        except Exception as e:
            st.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
supabase, naver_client_id, naver_client_secret, openai_api_key = init_clients()
embedding_model = load_embedding_model()

# ========================================
# 2. í•µì‹¬ ê²€ìƒ‰ í•¨ìˆ˜ë“¤
# ========================================

def generate_query_embedding(query: str) -> Optional[List[float]]:
    """ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±"""
    if not embedding_model or not query or len(query.strip()) < 2:
        return None
    
    try:
        cleaned_query = re.sub(r'\s+', ' ', query.strip())
        embedding = embedding_model.encode(cleaned_query, convert_to_tensor=False)
        embedding_list = embedding.tolist() if hasattr(embedding, 'tolist') else list(embedding)
        
        # 1536ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©
        if len(embedding_list) == 768:
            return embedding_list + [0.0] * 768
        elif len(embedding_list) == 1536:
            return embedding_list
        else:
            if len(embedding_list) < 1536:
                return embedding_list + [0.0] * (1536 - len(embedding_list))
            else:
                return embedding_list[:1536]
                
    except Exception as e:
        logger.error(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def semantic_search_qa(query: str, category_filter: str = None, top_k: int = 10) -> List[Dict]:
    """ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ QA ì°¾ê¸°"""
    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = generate_query_embedding(query)
        if not query_embedding:
            return []
        
        # ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰
        # PostgreSQLì˜ <=> ì—°ì‚°ì ì‚¬ìš© (cosine distance)
        base_query = supabase.table('product_qa').select(
            'id, product_name, brand, question, answer, question_type, recommendation_data, confidence_score'
        )
        
        # ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©
        if category_filter and category_filter != "ì „ì²´":
            # ì¹´í…Œê³ ë¦¬ ID ì¡°íšŒ
            category_result = supabase.table('product_categories').select('id').eq('category_name', category_filter).execute()
            if category_result.data:
                category_id = category_result.data[0]['id']
                base_query = base_query.eq('category_id', category_id)
        
        # ìµœì†Œ í’ˆì§ˆ ì¡°ê±´
        result = base_query.gte('confidence_score', 0.5).limit(top_k).execute()
        
        if not result.data:
            return []
        
        # ìœ ì‚¬ë„ ê³„ì‚° (í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ)
        qa_results = []
        for qa in result.data:
            # ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ì€ SQL í•¨ìˆ˜ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í…ìŠ¤íŠ¸ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´
            similarity = calculate_text_similarity(query, qa['question'], qa['answer'])
            
            if similarity > 0.3:  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
                qa['similarity'] = similarity
                qa_results.append(qa)
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        qa_results.sort(key=lambda x: x['similarity'], reverse=True)
        return qa_results[:top_k]
        
    except Exception as e:
        logger.error(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def calculate_text_similarity(query: str, question: str, answer: str) -> float:
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ì˜ ëŒ€ì•ˆ)"""
    try:
        # í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ìœ ì‚¬ë„
        query_words = set(re.findall(r'\w+', query.lower()))
        question_words = set(re.findall(r'\w+', question.lower()))
        answer_words = set(re.findall(r'\w+', answer.lower()))
        
        # ì§ˆë¬¸ê³¼ì˜ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 0.7)
        question_intersection = query_words.intersection(question_words)
        question_similarity = len(question_intersection) / max(len(query_words), 1) * 0.7
        
        # ë‹µë³€ê³¼ì˜ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 0.3)
        answer_intersection = query_words.intersection(answer_words)
        answer_similarity = len(answer_intersection) / max(len(query_words), 1) * 0.3
        
        return question_similarity + answer_similarity
        
    except Exception as e:
        logger.debug(f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

def search_products_with_ai_summary(query: str, category_filter: str = None) -> Dict:
    """QA ê²€ìƒ‰ + AI ìš”ì•½ì„ í†µí•œ ì œí’ˆ ì¶”ì²œ"""
    try:
        # 1. ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ QA ì°¾ê¸°
        relevant_qa = semantic_search_qa(query, category_filter, top_k=15)
        
        if not relevant_qa:
            return {"error": "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        # 2. ê²€ìƒ‰ëœ QAë“¤ì„ ChatGPTë¡œ ìš”ì•½í•˜ì—¬ ì¶”ì²œ ê²°ê³¼ ìƒì„±
        ai_summary = generate_ai_recommendation_summary(query, relevant_qa)
        
        return {
            "query": query,
            "relevant_qa": relevant_qa[:10],
            "ai_summary": ai_summary,
            "total_found": len(relevant_qa)
        }
        
    except Exception as e:
        logger.error(f"ì œí’ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

def generate_ai_recommendation_summary(query: str, qa_list: List[Dict]) -> str:
    """ê²€ìƒ‰ëœ QAë“¤ì„ ë°”íƒ•ìœ¼ë¡œ AI ì¶”ì²œ ìš”ì•½ ìƒì„±"""
    try:
        # QA ì •ë³´ ì •ë¦¬
        qa_text = []
        products_info = {}
        
        for qa in qa_list[:8]:  # ìƒìœ„ 8ê°œë§Œ ì‚¬ìš©
            qa_text.append(f"Q: {qa['question']}\nA: {qa['answer']}\n")
            
            product_name = qa['product_name']
            if product_name not in products_info:
                products_info[product_name] = {
                    'brand': qa.get('brand', ''),
                    'questions_count': 0,
                    'avg_confidence': 0,
                    'question_types': set()
                }
            
            products_info[product_name]['questions_count'] += 1
            products_info[product_name]['avg_confidence'] += qa.get('confidence_score', 0)
            products_info[product_name]['question_types'].add(qa.get('question_type', ''))
        
        # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        for product in products_info:
            count = products_info[product]['questions_count']
            if count > 0:
                products_info[product]['avg_confidence'] /= count
        
        # ChatGPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

ê´€ë ¨ ì œí’ˆ ì •ë³´:
{chr(10).join(qa_text[:2000])}  # í† í° ì œí•œ ê³ ë ¤

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œí’ˆ ì¶”ì²œì„ ìƒì„±í•´ì£¼ì„¸ìš”:

## ğŸ¯ AI ì¶”ì²œ ê²°ê³¼

### ğŸ’¡ ì¶”ì²œ ìš”ì•½
- ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ì œí’ˆ 1-2ê°œë¥¼ ê°„ë‹¨íˆ ì¶”ì²œ
- ì¶”ì²œ ì´ìœ ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…

### ğŸ“‹ ìƒì„¸ ì¶”ì²œ

**1ìˆœìœ„: [ì œí’ˆëª…]**
- ë¸Œëœë“œ: [ë¸Œëœë“œëª…]
- ì£¼ìš” íŠ¹ì§•: [íŠ¹ì§• 3ê°œ]
- ì¶”ì²œ ì´ìœ : [êµ¬ì²´ì ì¸ ì´ìœ ]
- ì˜ˆìƒ ê°€ê²©: [ê°€ê²©ëŒ€]

**2ìˆœìœ„: [ì œí’ˆëª…]** (ìˆëŠ” ê²½ìš°)
- ë¸Œëœë“œ: [ë¸Œëœë“œëª…] 
- ì£¼ìš” íŠ¹ì§•: [íŠ¹ì§• 3ê°œ]
- ì¶”ì²œ ì´ìœ : [êµ¬ì²´ì ì¸ ì´ìœ ]
- ì˜ˆìƒ ê°€ê²©: [ê°€ê²©ëŒ€]

### ğŸ” êµ¬ë§¤ ì‹œ ê³ ë ¤ì‚¬í•­
- ì£¼ìš” ì²´í¬í¬ì¸íŠ¸ 2-3ê°œ

ì‹¤ì œ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì¶”ì²œì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì œí’ˆ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì¶”ì²œì„ ì œê³µí•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.7
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        logger.error(f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return "AI ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”."

# ========================================
# 3. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ========================================

def get_database_stats() -> Dict:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© ì¡°íšŒ"""
    try:
        stats = {}
        
        # QA ë°ì´í„° í†µê³„
        qa_result = supabase.table('product_qa').select('id', count='exact').execute()
        stats['total_qa'] = qa_result.count if hasattr(qa_result, 'count') else len(qa_result.data)
        
        # ì›ë³¸ ë°ì´í„° í†µê³„
        raw_result = supabase.table('raw_product_data').select('id', count='exact').execute()
        stats['total_raw_data'] = raw_result.count if hasattr(raw_result, 'count') else len(raw_result.data)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_stats = supabase.table('product_categories').select('category_name').execute()
        stats['categories'] = [cat['category_name'] for cat in category_stats.data]
        
        # ì œí’ˆë³„ QA ìˆ˜ ìƒìœ„ 5ê°œ
        product_stats = supabase.table('product_qa_summary').select('*').limit(5).execute()
        stats['top_products'] = product_stats.data if product_stats.data else []
        
        return stats
        
    except Exception as e:
        logger.error(f"DB í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {}

def get_recent_qa_samples(limit: int = 5) -> List[Dict]:
    """ìµœê·¼ ìƒì„±ëœ QA ìƒ˜í”Œ ì¡°íšŒ"""
    try:
        result = supabase.table('product_qa').select(
            'product_name, question, answer, question_type, confidence_score, created_at'
        ).order('created_at', desc=True).limit(limit).execute()
        
        return result.data if result.data else []
        
    except Exception as e:
        logger.error(f"QA ìƒ˜í”Œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

# ========================================
# 4. Streamlit UI
# ========================================

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # ì œëª©
    st.title("ğŸ¤– AI ì œí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ")
    st.markdown("**ì‹œë§¨í‹± ê²€ìƒ‰ê³¼ AI ë¶„ì„ìœ¼ë¡œ ìµœì ì˜ ì œí’ˆì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤**")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("âš™ï¸ ì‹œìŠ¤í…œ í˜„í™©")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©
        st.markdown("### ğŸ“Š ë°ì´í„° í˜„í™©")
        
        with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
            db_stats = get_database_stats()
        
        if db_stats:
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì´ QA ìˆ˜", f"{db_stats.get('total_qa', 0):,}ê°œ")
            with col2:
                st.metric("ì›ë³¸ ë°ì´í„°", f"{db_stats.get('total_raw_data', 0):,}ê°œ")
            
            # ì¹´í…Œê³ ë¦¬ í˜„í™©
            if db_stats.get('categories'):
                st.markdown("**ë“±ë¡ëœ ì¹´í…Œê³ ë¦¬:**")
                for cat in db_stats['categories']:
                    st.markdown(f"â€¢ {cat}")
        
        st.markdown("---")
        
        # ìµœê·¼ QA ìƒ˜í”Œ
        st.markdown("### ğŸ“ ìµœê·¼ QA ìƒ˜í”Œ")
        recent_qa = get_recent_qa_samples(3)
        
        for i, qa in enumerate(recent_qa, 1):
            with st.expander(f"ìƒ˜í”Œ {i}: {qa['product_name']}", expanded=False):
                st.markdown(f"**Q:** {qa['question'][:50]}...")
                st.markdown(f"**A:** {qa['answer'][:80]}...")
                st.markdown(f"**íƒ€ì…:** {qa['question_type']}")
                st.markdown(f"**ì‹ ë¢°ë„:** {qa['confidence_score']:.2f}")
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ” ì œí’ˆ ê²€ìƒ‰ ë° ì¶”ì²œ")
        
        # ê²€ìƒ‰ì–´ ì…ë ¥
        query = st.text_input(
            "ê¶ê¸ˆí•œ ì œí’ˆì´ë‚˜ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: 200ë§Œì›ëŒ€ ë…¸íŠ¸ë¶ ì¶”ì²œí•´ì¤˜, ê²Œì´ë°ìš© ë…¸íŠ¸ë¶, ê°€ë²¼ìš´ ë…¸íŠ¸ë¶",
            help="êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        # ê²€ìƒ‰ ì˜µì…˜
        col_opt1, col_opt2 = st.columns(2)
        
        with col_opt1:
            categories = ["ì „ì²´"] + db_stats.get('categories', [])
            category_filter = st.selectbox("ì¹´í…Œê³ ë¦¬ í•„í„°", categories)
        
        with col_opt2:
            search_depth = st.selectbox(
                "ê²€ìƒ‰ ê¹Šì´",
                ["ë¹ ë¥¸ ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)", "ì •ë°€ ê²€ìƒ‰ (ìƒìœ„ 10ê°œ)", "ì „ì²´ ê²€ìƒ‰ (ìƒìœ„ 15ê°œ)"],
                index=1
            )
            
            depth_map = {
                "ë¹ ë¥¸ ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)": 5,
                "ì •ë°€ ê²€ìƒ‰ (ìƒìœ„ 10ê°œ)": 10,
                "ì „ì²´ ê²€ìƒ‰ (ìƒìœ„ 15ê°œ)": 15
            }
            top_k = depth_map[search_depth]
    
    with col2:
        st.markdown("### ğŸ’¡ ì‹œìŠ¤í…œ íŠ¹ì§•")
        st.markdown("""
        **ğŸ” ì‹œë§¨í‹± ê²€ìƒ‰**
        - ì˜ë¯¸ ê¸°ë°˜ ì œí’ˆ ê²€ìƒ‰
        - ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ ì´í•´
        - ë§¥ë½ ê³ ë ¤í•œ ì¶”ì²œ
        
        **ğŸ¤– AI ë¶„ì„**
        - ChatGPT ê¸°ë°˜ ìš”ì•½
        - ê°œì¸í™”ëœ ì¶”ì²œ
        - ì‹¤ì‹œê°„ ì •ë³´ ì¢…í•©
        
        **ğŸ“Š ë©€í‹°ì†ŒìŠ¤ ë°ì´í„°**
        - ì‡¼í•‘ëª° ê°€ê²© ì •ë³´
        - ì‚¬ìš©ì í›„ê¸° ë¶„ì„  
        - ë‰´ìŠ¤ ë° ë¦¬ë·° ì¢…í•©
        """)
    
    # ê²€ìƒ‰ ì‹¤í–‰
    if st.button("ğŸ” AI ì¶”ì²œ ë°›ê¸°", type="primary", use_container_width=True):
        if not query.strip():
            st.warning("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        # ê²€ìƒ‰ ì‹¤í–‰
        with st.spinner("AIê°€ ìµœì ì˜ ì œí’ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            search_result = search_products_with_ai_summary(
                query, 
                category_filter if category_filter != "ì „ì²´" else None
            )
        
        # ê²°ê³¼ í‘œì‹œ
        if "error" in search_result:
            st.error(f"âŒ {search_result['error']}")
            return
        
        # AI ìš”ì•½ í‘œì‹œ
        if search_result.get("ai_summary"):
            st.markdown("## ğŸ¤– AI ì¶”ì²œ ê²°ê³¼")
            st.markdown(search_result["ai_summary"])
        
        # ê²€ìƒ‰ëœ QA ìƒì„¸ ì •ë³´
        relevant_qa = search_result.get("relevant_qa", [])
        if relevant_qa:
            st.markdown("---")
            st.markdown("### ğŸ“š ê´€ë ¨ ì§ˆë¬¸-ë‹µë³€ ì •ë³´")
            st.caption(f"ì´ {search_result.get('total_found', 0)}ê°œ ì¤‘ ìƒìœ„ {len(relevant_qa)}ê°œ í‘œì‹œ")
            
            # QA í‘œì‹œ ì˜µì…˜
            show_details = st.checkbox("ìƒì„¸ QA ì •ë³´ ë³´ê¸°", value=False)
            
            if show_details:
                for i, qa in enumerate(relevant_qa, 1):
                    with st.expander(f"QA {i}: {qa['product_name']} ({qa['question_type']})", expanded=False):
                        col_qa1, col_qa2 = st.columns([1, 3])
                        
                        with col_qa1:
                            st.markdown("**ì œí’ˆ ì •ë³´**")
                            st.markdown(f"â€¢ **ì œí’ˆëª…:** {qa['product_name']}")
                            if qa.get('brand'):
                                st.markdown(f"â€¢ **ë¸Œëœë“œ:** {qa['brand']}")
                            st.markdown(f"â€¢ **ì§ˆë¬¸ ìœ í˜•:** {qa['question_type']}")
                            st.markdown(f"â€¢ **ì‹ ë¢°ë„:** {qa.get('confidence_score', 0):.2f}")
                            if 'similarity' in qa:
                                st.markdown(f"â€¢ **ìœ ì‚¬ë„:** {qa['similarity']:.2f}")
                        
                        with col_qa2:
                            st.markdown("**Q:** " + qa['question'])
                            st.markdown("**A:** " + qa['answer'])
                            
                            # ì¶”ì²œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                            if qa.get('recommendation_data'):
                                rec_data = qa['recommendation_data']
                                if isinstance(rec_data, dict):
                                    key_features = rec_data.get('key_features', [])
                                    if key_features:
                                        st.markdown("**ì£¼ìš” íŠ¹ì§•:** " + ", ".join(key_features))
            else:
                # ê°„ë‹¨í•œ QA ëª©ë¡ë§Œ í‘œì‹œ
                for i, qa in enumerate(relevant_qa[:5], 1):
                    st.markdown(f"**{i}. {qa['product_name']}** ({qa['question_type']})")
                    st.markdown(f"   Q: {qa['question']}")
                    st.markdown(f"   A: {qa['answer'][:150]}...")
                    st.markdown("")
        
        # ê²€ìƒ‰ í†µê³„
        st.markdown("---")
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        
        with col_stat1:
            st.metric("ê²€ìƒ‰ëœ QA", f"{len(relevant_qa)}ê°œ")
        with col_stat2:
            if relevant_qa:
                avg_confidence = sum(qa.get('confidence_score', 0) for qa in relevant_qa) / len(relevant_qa)
                st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.2f}")
        with col_stat3:
            unique_products = len(set(qa['product_name'] for qa in relevant_qa))
            st.metric("ê´€ë ¨ ì œí’ˆ ìˆ˜", f"{unique_products}ê°œ")

    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    with st.expander("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´", expanded=False):
        st.markdown("""
        **ğŸ”§ í•µì‹¬ ê¸°ìˆ :**
        - **ì‹œë§¨í‹± ê²€ìƒ‰**: SentenceTransformer + PostgreSQL pgvector
        - **AI ë¶„ì„**: ChatGPT-3.5 Turbo API
        - **ë°ì´í„° ì†ŒìŠ¤**: ë„¤ì´ë²„ ì‡¼í•‘/ë¸”ë¡œê·¸/ë‰´ìŠ¤ API
        - **ë°ì´í„°ë² ì´ìŠ¤**: Supabase (PostgreSQL)
        
        **ğŸ“Š ë°ì´í„° í”Œë¡œìš°:**
        1. ë„¤ì´ë²„ API â†’ ì›ë³¸ ë°ì´í„° ìˆ˜ì§‘
        2. ChatGPT â†’ ì§ˆë¬¸-ë‹µë³€ ìŒ ìƒì„±  
        3. SentenceTransformer â†’ ë²¡í„° ì„ë² ë”©
        4. ì‹œë§¨í‹± ê²€ìƒ‰ â†’ ê´€ë ¨ QA ì¶”ì¶œ
        5. ChatGPT â†’ ìµœì¢… ì¶”ì²œ ìš”ì•½
        
        **âœ¨ ì£¼ìš” íŠ¹ì§•:**
        - ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì •í™•í•œ ë§¤ì¹­
        - ì‹¤ì œ ì‚¬ìš©ì í›„ê¸° ë° ë‰´ìŠ¤ ì •ë³´ í™œìš©
        - AIê°€ ìƒì„±í•œ ë§ì¶¤í˜• ì¶”ì²œ
        - ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì í™”
        """)

if __name__ == "__main__":
    main()
