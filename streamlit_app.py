"""
ì™„ì „í•œ ë„ì–´ë½ ì¶”ì²œ Streamlit ì•±
GitHub Secretsì—ì„œ API í‚¤ë¥¼ ì½ì–´ì™€ì„œ ë„¤ì´ë²„ API ë°ì´í„° ìˆ˜ì§‘ ë° ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬í˜„
"""

import streamlit as st
import os
import json
import urllib.request
import urllib.parse
import re
import time
import hashlib
from datetime import datetime, date
from typing import List, Dict, Optional, Tuple
import logging

from supabase import create_client, Client
from sentence_transformers import SentenceTransformer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ” ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½ ì¶”ì²œ ì‹œìŠ¤í…œ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========================================
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ========================================

@st.cache_resource
def init_clients():
    """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (GitHub Secrets ë˜ëŠ” Streamlit Secrets ì‚¬ìš©)"""
    try:
        # GitHub Actions í™˜ê²½ì—ì„œëŠ” os.environ, Streamlit Cloudì—ì„œëŠ” st.secrets ì‚¬ìš©
        if hasattr(st, 'secrets') and 'SUPABASE_URL' in st.secrets:
            # Streamlit Secrets ì‚¬ìš©
            supabase_url = st.secrets["SUPABASE_URL"]
            supabase_key = st.secrets["SUPABASE_KEY"]
            naver_client_id = st.secrets["NAVER_CLIENT_ID"]
            naver_client_secret = st.secrets["NAVER_CLIENT_SECRET"]
        else:
            # í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© (GitHub Actions)
            supabase_url = os.environ.get("SUPABASE_URL")
            supabase_key = os.environ.get("SUPABASE_KEY")
            naver_client_id = os.environ.get("NAVER_CLIENT_ID")
            naver_client_secret = os.environ.get("NAVER_CLIENT_SECRET")
        
        # API í‚¤ í™•ì¸
        if not all([supabase_url, supabase_key, naver_client_id, naver_client_secret]):
            st.error("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GitHub Secrets ë˜ëŠ” Streamlit Secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        supabase = create_client(supabase_url, supabase_key)
        
        return supabase, naver_client_id, naver_client_secret
        
    except Exception as e:
        st.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        st.stop()

@st.cache_resource
def load_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ ë¡œë”©"""
    try:
        model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        return model
    except:
        try:
            model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            return model
        except Exception as e:
            st.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
supabase, naver_client_id, naver_client_secret = init_clients()
embedding_model = load_embedding_model()

# ========================================
# 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ========================================

def generate_embedding(text: str) -> Optional[List[float]]:
    """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (768ì°¨ì› â†’ 1536ì°¨ì› íŒ¨ë”©)"""
    if not embedding_model or not text or len(text.strip()) < 5:
        return None
    
    try:
        cleaned_text = re.sub(r'\s+', ' ', text.strip())
        cleaned_text = re.sub(r'[^\w\sê°€-í£\.]', ' ', cleaned_text)[:512]
        
        embedding = embedding_model.encode(cleaned_text, convert_to_tensor=False)
        embedding_list = embedding.tolist() if hasattr(embedding, 'tolist') else list(embedding)
        
        # 768ì°¨ì›ì„ 1536ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©
        if len(embedding_list) == 768:
            return embedding_list + [0.0] * 768
        elif len(embedding_list) == 1536:
            return embedding_list
        else:
            if len(embedding_list) < 1536:
                return embedding_list + [0.0] * (1536 - len(embedding_list))
            else:
                return embedding_list[:1536]
                
    except Exception as e:
        logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def search_naver_api(keyword: str, source_type: str, display: int = 100) -> List[Dict]:
    """ë„¤ì´ë²„ API ê²€ìƒ‰"""
    endpoint_map = {"ì‡¼í•‘": "shop", "ë¸”ë¡œê·¸": "blog", "ë‰´ìŠ¤": "news"}
    endpoint = endpoint_map.get(source_type)
    
    if not endpoint:
        return []
    
    try:
        # ì†ŒìŠ¤ë³„ ë§ì¶¤ ê²€ìƒ‰ì–´
        if source_type == "ì‡¼í•‘":
            search_query = keyword
        elif source_type == "ë¸”ë¡œê·¸":
            search_query = f"{keyword} í›„ê¸° ì„¤ì¹˜"
        else:  # ë‰´ìŠ¤
            search_query = f"{keyword} ë³´ì•ˆ í•´í‚¹"
        
        encoded_query = urllib.parse.quote(search_query)
        url = f"https://openapi.naver.com/v1/search/{endpoint}?query={encoded_query}&display={display}&sort=sim"
        
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", naver_client_id)
        request.add_header("X-Naver-Client-Secret", naver_client_secret)
        
        with urllib.request.urlopen(request, timeout=30) as response:
            if response.getcode() == 200:
                data = json.loads(response.read().decode('utf-8'))
                return data.get('items', [])
            else:
                return []
                
    except Exception as e:
        logger.error(f"ë„¤ì´ë²„ API ê²€ìƒ‰ ì‹¤íŒ¨ ({source_type}): {e}")
        return []

def process_and_save_data(keyword: str) -> Dict[str, int]:
    """ë„¤ì´ë²„ API ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥"""
    results = {"ì‡¼í•‘": 0, "ë¸”ë¡œê·¸": 0, "ë‰´ìŠ¤": 0}
    
    for source_type in ["ì‡¼í•‘", "ë¸”ë¡œê·¸", "ë‰´ìŠ¤"]:
        # API ê²€ìƒ‰
        items = search_naver_api(keyword, source_type)
        saved_count = 0
        
        for item in items:
            try:
                # ë°ì´í„° ì²˜ë¦¬
                if source_type == "ì‡¼í•‘":
                    processed_data = process_shopping_item(item)
                elif source_type == "ë¸”ë¡œê·¸":
                    processed_data = process_blog_item(item)
                else:  # ë‰´ìŠ¤
                    processed_data = process_news_item(item)
                
                if processed_data and save_to_database(processed_data):
                    saved_count += 1
                    
            except Exception as e:
                continue
        
        results[source_type] = saved_count
        time.sleep(0.5)  # API í˜¸ì¶œ ì œí•œ ê³ ë ¤
    
    return results

def process_shopping_item(item: Dict) -> Dict:
    """ì‡¼í•‘ ì•„ì´í…œ ì²˜ë¦¬"""
    title = re.sub('<[^<]+?>', '', item.get('title', ''))
    description = re.sub('<[^<]+?>', '', item.get('description', ''))
    
    content = f"ìƒí’ˆëª…: {title}\nì„¤ëª…: {description}\në¸Œëœë“œ: {item.get('brand', '')}\nê°€ê²©: {item.get('lprice', '')}ì›"
    
    return {
        'title': title,
        'content': content,
        'url': item.get('link', ''),
        'source_type': 'ì‡¼í•‘',
        'brand': item.get('brand', ''),
        'price_min': int(item.get('lprice', 0)) if item.get('lprice') else None,
        'price_max': int(item.get('hprice', 0)) if item.get('hprice') else None,
        'mall_name': item.get('mallName', ''),
        'source_metadata': item,
        'embedding': generate_embedding(content),
        # ì¶”ê°€ ì •ë³´
        'rating': None,  # ë„¤ì´ë²„ ì‡¼í•‘ì€ í‰ì  ì •ë³´ê°€ APIì— ì—†ìŒ
        'image_url': item.get('image', ''),
        'product_id': item.get('productId', '')
    }

def process_blog_item(item: Dict) -> Dict:
    """ë¸”ë¡œê·¸ ì•„ì´í…œ ì²˜ë¦¬"""
    title = re.sub('<[^<]+?>', '', item.get('title', ''))
    description = re.sub('<[^<]+?>', '', item.get('description', ''))
    
    content = f"ì œëª©: {title}\në‚´ìš©: {description}\në¸”ë¡œê±°: {item.get('bloggername', '')}"
    
    pub_date = None
    if item.get('postdate'):
        try:
            pub_date = datetime.strptime(item['postdate'], '%Y%m%d').date()
        except:
            pass
    
    return {
        'title': title,
        'content': content,
        'url': item.get('link', ''),
        'source_type': 'ë¸”ë¡œê·¸',
        'pub_date': pub_date,
        'blogger_name': item.get('bloggername', ''),
        'source_metadata': item,
        'embedding': generate_embedding(content)
    }

def process_news_item(item: Dict) -> Dict:
    """ë‰´ìŠ¤ ì•„ì´í…œ ì²˜ë¦¬"""
    title = re.sub('<[^<]+?>', '', item.get('title', ''))
    description = re.sub('<[^<]+?>', '', item.get('description', ''))
    
    content = f"ë‰´ìŠ¤ ì œëª©: {title}\në‚´ìš©: {description}"
    
    pub_date = None
    if item.get('pubDate'):
        try:
            pub_date = datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S %z').date()
        except:
            pass
    
    publisher = ""
    if item.get('originallink'):
        try:
            publisher = item['originallink'].replace('https://', '').replace('http://', '').split('/')[0]
        except:
            pass
    
    return {
        'title': title,
        'content': content,
        'url': item.get('link', ''),
        'source_type': 'ë‰´ìŠ¤',
        'pub_date': pub_date,
        'publisher': publisher,
        'source_metadata': item,
        'embedding': generate_embedding(content)
    }

def save_to_database(processed_data: Dict) -> bool:
    """ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        # ì¤‘ë³µ í™•ì¸
        existing = supabase.table('documents').select('id').eq('url', processed_data['url']).execute()
        
        if existing.data:
            return False  # ì´ë¯¸ ì¡´ì¬
        
        # documents í…Œì´ë¸”ì— ì €ì¥
        doc_data = {
            'title': processed_data['title'],
            'content': processed_data['content'],
            'url': processed_data['url'],
            'source_type': processed_data['source_type'],
            'embedding': processed_data.get('embedding'),
            'source_metadata': processed_data['source_metadata'],
            'brand': processed_data.get('brand'),
            'price_min': processed_data.get('price_min'),
            'price_max': processed_data.get('price_max'),
            'pub_date': processed_data.get('pub_date').isoformat() if processed_data.get('pub_date') else None,
            'publisher': processed_data.get('publisher'),
            'blogger_name': processed_data.get('blogger_name'),
            'mall_name': processed_data.get('mall_name')
        }
        
        result = supabase.table('documents').insert(doc_data).execute()
        document_id = result.data[0]['id']
        
        # ì†ŒìŠ¤ë³„ íŠ¹í™” í…Œì´ë¸”ì— ì €ì¥
        if processed_data['source_type'] == 'ì‡¼í•‘':
            save_product_data(document_id, processed_data)
        elif processed_data['source_type'] == 'ë¸”ë¡œê·¸':
            save_blog_data(document_id, processed_data)
        elif processed_data['source_type'] == 'ë‰´ìŠ¤':
            save_news_data(document_id, processed_data)
        
        return True
        
    except Exception as e:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_product_data(document_id: int, processed_data: Dict):
    """products í…Œì´ë¸”ì— ì €ì¥"""
    try:
        product_data = {
            'document_id': document_id,
            'product_name': processed_data['title'],
            'brand': processed_data.get('brand'),
            'lprice': processed_data.get('price_min'),
            'hprice': processed_data.get('price_max'),
            'mall_name': processed_data.get('mall_name'),
            'product_id': processed_data.get('product_id'),
            'image_url': processed_data.get('image_url'),
            'product_specs': processed_data['source_metadata'],
            'rating': processed_data.get('rating', 0.0),
            'review_count': 0
        }
        supabase.table('products').insert(product_data).execute()
    except Exception as e:
        logger.debug(f"ì œí’ˆ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

def save_blog_data(document_id: int, processed_data: Dict):
    """blog_posts í…Œì´ë¸”ì— ì €ì¥"""
    try:
        blog_data = {
            'document_id': document_id,
            'blogger_name': processed_data.get('blogger_name'),
            'blogger_id': processed_data['source_metadata'].get('bloggername'),
            'blog_url': processed_data['source_metadata'].get('bloggerlink'),
            'post_date': processed_data.get('pub_date').isoformat() if processed_data.get('pub_date') else None,
            'review_type': 'product_review'
        }
        supabase.table('blog_posts').insert(blog_data).execute()
    except Exception as e:
        logger.debug(f"ë¸”ë¡œê·¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

def save_news_data(document_id: int, processed_data: Dict):
    """news_articles í…Œì´ë¸”ì— ì €ì¥"""
    try:
        keywords = [word for word in processed_data['title'].split() if len(word) > 2][:10]
        
        news_data = {
            'document_id': document_id,
            'publisher': processed_data.get('publisher'),
            'original_url': processed_data['source_metadata'].get('originallink'),
            'pub_date': processed_data.get('pub_date').isoformat() if processed_data.get('pub_date') else None,
            'article_type': 'analysis',
            'keywords': keywords
        }
        supabase.table('news_articles').insert(news_data).execute()
    except Exception as e:
        logger.debug(f"ë‰´ìŠ¤ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

def get_doorlock_recommendations(query: str = "ë„ì–´ë½") -> List[Dict]:
    """ë„ì–´ë½ ì¶”ì²œ ê²°ê³¼ ì¡°íšŒ"""
    try:
        result = supabase.rpc('get_doorlock_recommendations', {'query_text': query}).execute()
        return result.data if result.data else []
    except Exception as e:
        logger.error(f"ì¶”ì²œ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def create_sample_product_data():
    """ìƒ˜í”Œ ì œí’ˆ ë°ì´í„° ìƒì„± (AI íŠ¹ì§• ì ìˆ˜ í¬í•¨)"""
    try:
        # ê¸°ì¡´ product_masterì— AI ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        sample_products = [
            {
                'canonical_name': 'ì‚¼ì„± SHP-DP930',
                'features': {'ì„¤ì¹˜_ê°„í¸ì„±': 4.2, 'ë³´ì•ˆì„±': 3.8, 'ê°€ê²©_ê²½ìŸë ¥': 3.5, 'ì‚¬ìš©ì_ë§Œì¡±ë„': 4.0}
            },
            {
                'canonical_name': 'ê²Œì´íŠ¸ë§¨ F50', 
                'features': {'ì„¤ì¹˜_ê°„í¸ì„±': 3.5, 'ë³´ì•ˆì„±': 4.9, 'ê°€ê²©_ê²½ìŸë ¥': 4.2, 'ì‚¬ìš©ì_ë§Œì¡±ë„': 4.3}
            },
            {
                'canonical_name': 'LG ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½',
                'features': {'ì„¤ì¹˜_ê°„í¸ì„±': 3.8, 'ë³´ì•ˆì„±': 4.1, 'ê°€ê²©_ê²½ìŸë ¥': 3.8, 'ì‚¬ìš©ì_ë§Œì¡±ë„': 3.9}
            }
        ]
        
        for product in sample_products:
            # product_master ì¡°íšŒ
            master_result = supabase.table('product_master').select('id').eq('canonical_name', product['canonical_name']).execute()
            
            if master_result.data:
                master_id = master_result.data[0]['id']
                
                # product_mentionsì— AI ë¶„ì„ ê²°ê³¼ ì €ì¥
                mention_data = {
                    'product_master_id': master_id,
                    'product_name': product['canonical_name'],
                    'brand': product['canonical_name'].split()[0],
                    'mention_type': 'main_product',
                    'sentiment': 'positive',
                    'confidence_score': 0.9,
                    'feature_scores': product['features'],
                    'mention_context': f"{product['canonical_name']} ì œí’ˆ ë¶„ì„ ê²°ê³¼"
                }
                
                supabase.table('product_mentions').insert(mention_data).execute()
        
        # product_master ì ìˆ˜ ì—…ë°ì´íŠ¸
        supabase.rpc('update_product_master_scores').execute()
        
    except Exception as e:
        logger.error(f"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")

# ========================================
# 3. Streamlit UI
# ========================================

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # ì œëª©
    st.title("ğŸ” ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½ ì¶”ì²œ ì‹œìŠ¤í…œ")
    st.markdown("**AIê°€ ë„¤ì´ë²„ ì‡¼í•‘, ë¸”ë¡œê·¸, ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë„ì–´ë½ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.**")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
        st.markdown("### ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©")
        try:
            # ë¬¸ì„œ ìˆ˜ ì¡°íšŒ
            docs_result = supabase.table('documents').select('id', count='exact').execute()
            total_docs = docs_result.count if hasattr(docs_result, 'count') else len(docs_result.data)
            
            st.metric("ì´ ë¬¸ì„œ ìˆ˜", f"{total_docs:,}ê°œ")
            
            # ì œí’ˆ ìˆ˜ ì¡°íšŒ
            products_result = supabase.table('product_master').select('id', count='exact').execute()
            total_products = products_result.count if hasattr(products_result, 'count') else len(products_result.data)
            
            st.metric("ë“±ë¡ ì œí’ˆ ìˆ˜", f"{total_products:,}ê°œ")
            
        except Exception as e:
            st.error("DB ì—°ê²° ì˜¤ë¥˜")
        
        st.markdown("---")
        
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë²„íŠ¼
        if st.button("ğŸ¯ ìƒ˜í”Œ ë°ì´í„° ìƒì„±", help="í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"):
            with st.spinner("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘..."):
                create_sample_product_data()
                st.success("âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
                st.rerun()
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ” ë„ì–´ë½ ê²€ìƒ‰ ë° ì¶”ì²œ")
        
        # ê²€ìƒ‰ì–´ ì…ë ¥
        query = st.text_input(
            "ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”",
            placeholder="ë„ì–´ë½ ì¶”ì²œí•´ì¤˜",
            help="ì˜ˆ: ë„ì–´ë½ ì¶”ì²œí•´ì¤˜, ì„¤ì¹˜ ê°„ë‹¨í•œ ë„ì–´ë½, ë³´ì•ˆ ì¢‹ì€ ë„ì–´ë½"
        )
        
        # ê²€ìƒ‰ ì˜µì…˜
        col_search1, col_search2 = st.columns(2)
        
        with col_search1:
            search_mode = st.selectbox(
                "ê²€ìƒ‰ ëª¨ë“œ",
                ["ê¸°ì¡´ ë°ì´í„° ê²€ìƒ‰", "ìƒˆ ë°ì´í„° ìˆ˜ì§‘ í›„ ê²€ìƒ‰"],
                help="ê¸°ì¡´ ë°ì´í„°ë¡œ ë¹ ë¥¸ ê²€ìƒ‰ ë˜ëŠ” ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ í›„ ê²€ìƒ‰"
            )
        
        with col_search2:
            collect_sources = st.multiselect(
                "ìˆ˜ì§‘ ì†ŒìŠ¤ (ìƒˆ ë°ì´í„° ìˆ˜ì§‘ ì‹œ)",
                ["ì‡¼í•‘", "ë¸”ë¡œê·¸", "ë‰´ìŠ¤"],
                default=["ì‡¼í•‘", "ë¸”ë¡œê·¸", "ë‰´ìŠ¤"]
            )
    
    with col2:
        st.markdown("### ğŸ’¡ ì¶”ì²œ ì‹œìŠ¤í…œ íŠ¹ì§•")
        st.markdown("""
        **ğŸ›ï¸ ì¢…í•© ë¶„ì„**
        - ê°€ê²© ì •ë³´ (ì‡¼í•‘)
        - ì‚¬ìš©ì í›„ê¸° (ë¸”ë¡œê·¸)  
        - ë³´ì•ˆ ë‰´ìŠ¤ (ë‰´ìŠ¤)
        
        **ğŸ¤– AI í‰ê°€**
        - ì„¤ì¹˜ ê°„í¸ì„±
        - ë³´ì•ˆì„±
        - ê°€ê²© ê²½ìŸë ¥
        - ì‚¬ìš©ì ë§Œì¡±ë„
        """)
    
    # ê²€ìƒ‰ ì‹¤í–‰
    if st.button("ğŸ” ë„ì–´ë½ ì¶”ì²œ ë°›ê¸°", type="primary", use_container_width=True):
        if not query.strip():
            st.warning("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        # ìƒˆ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“œ
        if search_mode == "ìƒˆ ë°ì´í„° ìˆ˜ì§‘ í›„ ê²€ìƒ‰" and collect_sources:
            st.markdown("### ğŸ“¡ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            with st.spinner("ë„¤ì´ë²„ APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
                try:
                    results = process_and_save_data(query)
                    
                    progress_bar.progress(100)
                    
                    # ìˆ˜ì§‘ ê²°ê³¼ í‘œì‹œ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸ›ï¸ ì‡¼í•‘", f"{results['ì‡¼í•‘']}ê°œ")
                    with col2:
                        st.metric("âœï¸ ë¸”ë¡œê·¸", f"{results['ë¸”ë¡œê·¸']}ê°œ")
                    with col3:
                        st.metric("ğŸ“° ë‰´ìŠ¤", f"{results['ë‰´ìŠ¤']}ê°œ")
                    
                    st.success(f"âœ… ì´ {sum(results.values())}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
                    
                except Exception as e:
                    st.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                    return
                finally:
                    progress_bar.empty()
                    status_text.empty()
        
        # ì¶”ì²œ ê²°ê³¼ ì¡°íšŒ ë° í‘œì‹œ
        st.markdown("### ğŸ¯ ë„ì–´ë½ ì¶”ì²œ ê²°ê³¼")
        
        with st.spinner("AIê°€ ì¶”ì²œ ê²°ê³¼ë¥¼ ë¶„ì„ ì¤‘..."):
            try:
                recommendations = get_doorlock_recommendations(query)
                
                if not recommendations:
                    st.warning("âš ï¸ ì¶”ì²œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
                    return
                
                # ì¶”ì²œ ê²°ê³¼ë¥¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
                installation_recs = [r for r in recommendations if r['recommendation_type'] == 'ì„¤ì¹˜ ê°„í¸ì„± ê¸°ì¤€ ì¶”ì²œ']
                security_recs = [r for r in recommendations if r['recommendation_type'] == 'ë³´ì•ˆì„± ê¸°ì¤€ ì¶”ì²œ']
                
                # ì„¤ì¹˜ ê°„í¸ì„± ê¸°ì¤€ ì¶”ì²œ
                if installation_recs:
                    st.markdown("#### ğŸ”§ ì„¤ì¹˜ ê°„í¸ì„± ê¸°ì¤€ ì¶”ì²œ:")
                    
                    for i, rec in enumerate(installation_recs, 1):
                        with st.container():
                            st.markdown(f"**{i}. {rec['product_name']}**")
                            
                            col1, col2 = st.columns([1, 1])
                            
                            with col1:
                                st.markdown(f"â€¢ **ì‡¼í•‘**: {rec['price_info']}, {rec['rating_info']}")
                                
                                # ë¸”ë¡œê·¸ í›„ê¸°
                                if rec['blog_quotes']:
                                    quotes = [q for q in rec['blog_quotes'] if q and len(q) > 5]
                                    if quotes:
                                        st.markdown(f"â€¢ **ë¸”ë¡œê·¸ í›„ê¸°**: \"{quotes[0][:50]}...\"")
                            
                            with col2:
                                st.markdown(f"â€¢ **{rec['score_display']}**")
                                st.markdown(f"â€¢ **{rec['star_rating']}** ({rec['star_rating'].count('â­')}/5)")
                            
                            st.markdown("---")
                
                # ë³´ì•ˆì„± ê¸°ì¤€ ì¶”ì²œ  
                if security_recs:
                    st.markdown("#### ğŸ”’ ë³´ì•ˆì„± ê¸°ì¤€ ì¶”ì²œ:")
                    
                    for i, rec in enumerate(security_recs, 1):
                        with st.container():
                            st.markdown(f"**{i}. {rec['product_name']}**")
                            
                            col1, col2 = st.columns([1, 1])
                            
                            with col1:
                                # ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸
                                if rec['news_highlights']:
                                    highlights = [h for h in rec['news_highlights'] if h]
                                    if highlights:
                                        st.markdown(f"â€¢ **ë‰´ìŠ¤**: \"{highlights[0]}\"")
                                
                                # ë¸”ë¡œê·¸ í›„ê¸°
                                if rec['blog_quotes']:
                                    quotes = [q for q in rec['blog_quotes'] if q and len(q) > 5]
                                    if quotes:
                                        st.markdown(f"â€¢ **ë¸”ë¡œê·¸**: \"{quotes[0][:50]}...\"")
                            
                            with col2:
                                st.markdown(f"â€¢ **{rec['score_display']}**")
                                st.markdown(f"â€¢ **{rec['star_rating']}** ({rec['star_rating'].count('â­')}/5)")
                            
                            st.markdown("---")
                
            except Exception as e:
                st.error(f"âŒ ì¶”ì²œ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                st.info("ğŸ’¡ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”.")

    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    with st.expander("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´", expanded=False):
        st.markdown("""
        **ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ:**
        - **Frontend**: Streamlit
        - **Database**: Supabase (PostgreSQL + pgvector)
        - **AI/ML**: SentenceTransformer, OpenAI
        - **API**: ë„¤ì´ë²„ ê²€ìƒ‰ API
        
        **ğŸ“Š ë°ì´í„° ì†ŒìŠ¤:**
        - ë„¤ì´ë²„ ì‡¼í•‘: ì œí’ˆ ì •ë³´, ê°€ê²©, ìŠ¤í™
        - ë„¤ì´ë²„ ë¸”ë¡œê·¸: ì‚¬ìš©ì í›„ê¸°, ì„¤ì¹˜ ê²½í—˜
        - ë„¤ì´ë²„ ë‰´ìŠ¤: ë³´ì•ˆ ì´ìŠˆ, ì—…ê³„ ë™í–¥
        
        **ğŸ¤– AI ë¶„ì„:**
        - ì„¤ì¹˜ ê°„í¸ì„± (1-5ì )
        - ë³´ì•ˆì„± (1-5ì ) 
        - ê°€ê²© ê²½ìŸë ¥ (1-5ì )
        - ì‚¬ìš©ì ë§Œì¡±ë„ (1-5ì )
        """)

if __name__ == "__main__":
    main()
